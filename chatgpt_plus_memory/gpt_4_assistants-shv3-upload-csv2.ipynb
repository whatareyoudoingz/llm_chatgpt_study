{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import openai\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.6\n"
     ]
    }
   ],
   "source": [
    "# assert version is > 1.0.0\n",
    "assert openai.__version__ > \"1.0.0\", \"Please upgrade the OpenAI Python client: pip install -U openai\"\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (1.3.6)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from openai) (1.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from openai) (4.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\envs\\kagpt\\lib\\site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files for context of the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# # get all python files inside data/tinygrad even inside subfolders etc\n",
    "# filepath = \"data/tinygrad/\"\n",
    "# python_files = glob.glob(filepath + \"**/*.py\", recursive=True)\n",
    "# print(f\"Found {len(python_files)} python files\")\n",
    "\n",
    "# def is_usefull_python_file(python_file_path):\n",
    "#     # just to remove useless file for the assistant \n",
    "#     bad_strings_to_not_match = [\"test\", \"mlperf\", \"setup.py\",\n",
    "#                                 \"runtime\", \"examples\", \"renderer\",\n",
    "#                                  \"openpilot\", \"models\",\"adreno\", \n",
    "#                                  \"extra\", \"jit\", \"sz.py\"]\n",
    "#     if \"resnet.py\" in python_file_path:\n",
    "#         return True\n",
    "#     for bad_string in bad_strings_to_not_match:\n",
    "#         if bad_string in python_file_path:\n",
    "#             return False\n",
    "#     return True\n",
    "# # print files with model in the path\n",
    "\n",
    "# print(\"Files with model in the path\")\n",
    "# print(list(filter(lambda x: \"model\" in x, python_files)))\n",
    "\n",
    "\n",
    "# python_files = list(filter(is_usefull_python_file, python_files))\n",
    "# print(f\"Found {len(python_files)} python files after filtering\")\n",
    "# assert len(python_files) <= 20, \"Openai limit is 20 files\"\n",
    "# print(\"\\n\".join(python_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 python files\n",
      "Files with model in the path\n",
      "[]\n",
      "Found 1 python files after filtering\n",
      "data\\qa1-simp.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# get all python files inside data/tinygrad even inside subfolders etc\n",
    "filepath = \"data/\"\n",
    "python_files = glob.glob(filepath + \"**/*.csv\", recursive=True)\n",
    "print(f\"Found {len(python_files)} python files\")\n",
    "\n",
    "def is_usefull_python_file(python_file_path):\n",
    "    # just to remove useless file for the assistant \n",
    "    bad_strings_to_not_match = [\"test\", \"mlperf\", \"setup.py\",\n",
    "                                \"runtime\", \"examples\", \"renderer\",\n",
    "                                 \"openpilot\", \"models\",\"adreno\", \n",
    "                                 \"extra\", \"jit\", \"sz.py\"]\n",
    "    if \"resnet.py\" in python_file_path:\n",
    "        return True\n",
    "    for bad_string in bad_strings_to_not_match:\n",
    "        if bad_string in python_file_path:\n",
    "            return False\n",
    "    return True\n",
    "# print files with model in the path\n",
    "\n",
    "print(\"Files with model in the path\")\n",
    "print(list(filter(lambda x: \"model\" in x, python_files)))\n",
    "\n",
    "\n",
    "python_files = list(filter(is_usefull_python_file, python_files))\n",
    "print(f\"Found {len(python_files)} python files after filtering\")\n",
    "assert len(python_files) <= 20, \"Openai limit is 20 files\"\n",
    "print(\"\\n\".join(python_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the files to Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95b24c358b7416781f1de3717f8841e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "client = OpenAI()\n",
    "uploaded_files = []\n",
    "for filename in tqdm(python_files):\n",
    "    file_obj = client.files.create(\n",
    "        file=open(filename, 'rb'),\n",
    "        purpose='assistants',\n",
    "        \n",
    "    )\n",
    "    uploaded_files.append(file_obj.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-JJ99FhhmXersv1NO2pfIicHH']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinygrad_assistant = openai.beta.assistants.create(\n",
    "    instructions=\"You are helping coders understand the tinygrad library. You have access to the source code of the codebase. You are a helpful tinygrad assistant.\",\n",
    "    name=\"Tinygrad Assistant (API)\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    file_ids=uploaded_files,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an empty thread\n",
    "Empty threads are not linked to an assistant yet. Multiple assistants can be used inside the same thread :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = openai.beta.threads.create()\n",
    "thread_id = thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Q가 말한 것은 몇가지야?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Run completed in 00:00:23\n"
     ]
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread_id,\n",
    "    role=\"user\",\n",
    "    content=query,\n",
    ")\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread_id,\n",
    "    assistant_id=tinygrad_assistant.id)\n",
    "\n",
    "import time\n",
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n",
    "    if run.completed_at:\n",
    "        elapsed = run.completed_at - run.created_at\n",
    "        elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))\n",
    "        print(f\"Run completed in {elapsed}\")\n",
    "        break\n",
    "    print(\"Waiting 1sec\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q가 말한 것은 총 7가지입니다. 다음은 낮은 자존감으로 인해 나타나는 영향들입니다:\n",
      "\n",
      "1. 일이 잘못되면 스스로를 낮추거나 의심하거나 비난한다.\n",
      "2. 일이 잘 풀리지 않을 거라 생각하고 도전이나 기회를 피한다.\n",
      "3. 다른 사람들보다 능력이 부족하다고 믿고 적게 성취한다.\n",
      "4. 비판이나 거절에 화를 내거나 괴로워한다.\n",
      "5. 다른 사람을 기쁘게 하기 위해 상대에게 맞추거나 자신을 깎아내린다.\n",
      "6. 여가 활동을 많이 하지 않고 판단/평가 받을 수 있는 활동을 피한다.\n",
      "7. 자기 관리에 영향을 받아 소중히 여기지 않고, 외모 관리에 소홀하거나 그 반대로 완벽해 보이려 애쓴다.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "last_message = messages.data[0]\n",
    "\n",
    "text = last_message.content[0].text.value\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

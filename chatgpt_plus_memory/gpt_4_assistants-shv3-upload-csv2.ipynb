{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 참고\n",
    "    - 블로그 : https://pkgpl.org/2023/11/08/openai-assistants-api로-대화-내용-저장하기/\n",
    "    - 레퍼런스 : https://platform.openai.com/docs/assistants/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- openai assistents api가 langchain과 다른점 : memory가 아니라 thread를 이용해 대화를 저장한다.\n",
    "    - 장점 : 토큰 제한을 알아서 맞춰준다.\n",
    "    - 단점 : 커스터마이징할 수 있는 부분이 제한적이고, 대화 내용을 최대한 보존하는 방식으로 토큰 소모가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 용어 정리\n",
    "    - **Assistant**: 도구들을 사용할 수 있는 **거대 언어 모델**(GPT 모델들)입니다.\n",
    "    - **`Thread`** : **`Message들을 저장하는 대화`** 입니다.\n",
    "    - **Message**: 대화에서 주고 받는 메시지들로, 텍스트 외에도 **이미지나 파일을 포함**할 수 있습니다.\n",
    "    - **`Run`**: Assistant가 Thread에 저장된 Message들을 읽고 **`LLM의 응답 Message를 추가하는 과정`** 입니다.\n",
    "    - **Run Step**: Run을 실행할 때 단순히 LLM의 응답을 추가하는 경우도 있지만, 외부 도구들(Tools)을 사용한 후 결과를 이용해 응답하는 경우도 있습니다. **어떤 세부 단계를 거쳐 응답했는지 확인하고 싶을 때** Run Step을 이용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run상태\n",
    "    - **기본** 응답: **queued → in_progress → completed**\n",
    "    - Function calling **`(사용자가 제공한 Tool) 사용`** 시: queued → in_progress → **`requires_action → (함수 호출 결과 입력 후 다시 Run) → queued → in_progress`** → completed\n",
    "    - 응답 시간이 **오래** 걸리면: queued → in_progress → **expired**\n",
    "    - 응답 **실패**시: queued → in_progress → **failed**\n",
    "    - **사용자가 취소**할 경우: queued → in_progress → **(사용자가 취소) → cancelling → cancelled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/t16user5/gpt4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.7\n"
     ]
    }
   ],
   "source": [
    "# assert version is > 1.0.0\n",
    "assert openai.__version__ > \"1.0.0\", \"Please upgrade the OpenAI Python client: pip install -U openai\"\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.10/site-packages (1.3.7)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /opt/anaconda3/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.10/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.10/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.10/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/anaconda3/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /opt/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv 파일 업로드 \n",
    "## Files for context of the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 python files\n",
      "Files with model in the path\n",
      "[]\n",
      "Found 1 python files after filtering\n",
      "data/qa1-simp.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# data 폴더 내부 및 하위 폴더에서 모든 Python 파일 가져오기\n",
    "filepath = \"data/\"\n",
    "python_files = glob.glob(filepath + \"**/*.csv\", recursive=True)\n",
    "print(f\"Found {len(python_files)} python files\")\n",
    "\n",
    "def is_usefull_python_file(python_file_path):\n",
    "    # Assistant에 대한 불필요한 파일 제거를 위한 함수\n",
    "    bad_strings_to_not_match = [\"test\", \"mlperf\", \"setup.py\",\n",
    "                                \"runtime\", \"examples\", \"renderer\",\n",
    "                                 \"openpilot\", \"models\",\"adreno\", \n",
    "                                 \"extra\", \"jit\", \"sz.py\"]\n",
    "    if \"resnet.py\" in python_file_path:\n",
    "        return True\n",
    "    for bad_string in bad_strings_to_not_match:\n",
    "        if bad_string in python_file_path:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# 파일 이름에 \"model\"이 포함된 파일 출력\n",
    "print(\"Files with model in the path\")\n",
    "print(list(filter(lambda x: \"model\" in x, python_files)))\n",
    "\n",
    "# 유용한 Python 파일만 필터링 후 출력\n",
    "python_files = list(filter(is_usefull_python_file, python_files))\n",
    "print(f\"Found {len(python_files)} python files after filtering\")\n",
    "assert len(python_files) <= 20, \"Openai limit is 20 files\"\n",
    "print(\"\\n\".join(python_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the files to Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e701d25601d4513bdfc94acfcc7ecce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "client = OpenAI()\n",
    "uploaded_files = []\n",
    "# tqdm을 사용하여 파일 업로드 진행 상황 표시\n",
    "for filename in tqdm(python_files):\n",
    "    file_obj = client.files.create(\n",
    "        file=open(filename, 'rb'),\n",
    "        purpose='assistants',\n",
    "        \n",
    "    )\n",
    "    uploaded_files.append(file_obj.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-xsaPm7iZhUDzz9QFhhHXEEnB']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Assistant) LLM 만들기\n",
    "- Openai의 서버에 저장, 고유한 id보유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinygrad_assistant = openai.beta.assistants.create(\n",
    "    instructions=\"You are helping coders understand the tinygrad library. You have access to the source code of the codebase. You are a helpful tinygrad assistant.\",\n",
    "    name=\"Tinygrad Assistant (API)\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    file_ids=uploaded_files,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread 만들기 (Create an empty thread)\n",
    "Empty threads are not linked to an assistant yet. Multiple assistants can be used inside the same thread :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Run completed in 00:00:11\n"
     ]
    }
   ],
   "source": [
    "# 빈 thread 생성\n",
    "thread = openai.beta.threads.create()\n",
    "thread_id = thread.id\n",
    "\n",
    "# 메시지 생성\n",
    "query = \"Q가 말한 것은 몇가지야?\"\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread_id,\n",
    "    role=\"user\",\n",
    "    content=query,\n",
    ")\n",
    "\n",
    "# run 상태확인\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread_id,\n",
    "    assistant_id=tinygrad_assistant.id)\n",
    "\n",
    "# 응답 소요시간 및 완성 체크\n",
    "import time\n",
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id, \n",
    "        run_id=run.id)\n",
    "    if run.completed_at:\n",
    "        elapsed = run.completed_at - run.created_at\n",
    "        elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))\n",
    "        print(f\"Run completed in {elapsed}\")\n",
    "        break\n",
    "    print(\"Waiting 1sec\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Thread에 추가된 응답 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q가 말한 것은 총 7가지입니다. 다음과 같습니다:\n",
      "\n",
      "1. 일이 잘못되면 스스로를 낮추거나 의심하거나 비난한다.\n",
      "2. 일이 잘 풀리지 않을 거라 생각한다.\n",
      "3. 다른 사람들보다 능력이 부족하다고 믿어 자신의 능력보다 적게 성취한다.\n",
      "4. 비판, 거절에 화를 내거나 괴로워한다.\n",
      "5. 다른 사람을 기쁘게 하기 위해 상대에게 맞추거나 자신을 깎아내린다.\n",
      "6. 여가 활동을 많이 하지 않는다.\n",
      "7. 자기 관리에 영향을 받는다.\n",
      "\n",
      "이는 낮은 자존감으로 인해 나타나는 영향들을 나열한 것입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "last_message = messages.data[0]\n",
    "\n",
    "text = last_message.content[0].text.value\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################질문################\n",
      "user: Q가 말한 것은 몇가지야?\n",
      "################응답################\n",
      "assistant: Q가 말한 것은 총 7가지입니다. 다음과 같습니다:\n",
      "\n",
      "1. 일이 잘못되면 스스로를 낮추거나 의심하거나 비난한다.\n",
      "2. 일이 잘 풀리지 않을 거라 생각한다.\n",
      "3. 다른 사람들보다 능력이 부족하다고 믿어 자신의 능력보다 적게 성취한다.\n",
      "4. 비판, 거절에 화를 내거나 괴로워한다.\n",
      "5. 다른 사람을 기쁘게 하기 위해 상대에게 맞추거나 자신을 깎아내린다.\n",
      "6. 여가 활동을 많이 하지 않는다.\n",
      "7. 자기 관리에 영향을 받는다.\n",
      "\n",
      "이는 낮은 자존감으로 인해 나타나는 영향들을 나열한 것입니다.\n"
     ]
    }
   ],
   "source": [
    "for msg in reversed(messages.data):\n",
    "    if msg.role=='user':\n",
    "        print(\"################질문################\")\n",
    "    else:\n",
    "        print(\"################응답################\")\n",
    "    print(f\"{msg.role}: {msg.content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 메시지 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Run completed in 00:00:21\n"
     ]
    }
   ],
   "source": [
    "# 메시지 생성\n",
    "query = \"Q을 위해 어떤 그림, 음악, 영상 컨텐츠가 위로가 될까?\"\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread_id,\n",
    "    role=\"user\",\n",
    "    content=query,\n",
    ")\n",
    "\n",
    "# run 상태확인\n",
    "## run 생성\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread_id,\n",
    "    assistant_id=tinygrad_assistant.id)\n",
    "\n",
    "## 응답 소요시간 및 상태 체크\n",
    "import time\n",
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id, \n",
    "        run_id=run.id)\n",
    "    if run.completed_at:\n",
    "        elapsed = run.completed_at - run.created_at\n",
    "        elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))\n",
    "        print(f\"Run completed in {elapsed}\")\n",
    "        break\n",
    "    print(\"Waiting 1sec\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ################질문################\n",
      "user: Q가 말한 것은 몇가지야?\n",
      "################응답################\n",
      "assistant: Q가 말한 것은 총 7가지입니다. 다음과 같습니다:\n",
      "\n",
      "1. 일이 잘못되면 스스로를 낮추거나 의심하거나 비난한다.\n",
      "2. 일이 잘 풀리지 않을 거라 생각한다.\n",
      "3. 다른 사람들보다 능력이 부족하다고 믿어 자신의 능력보다 적게 성취한다.\n",
      "4. 비판, 거절에 화를 내거나 괴로워한다.\n",
      "5. 다른 사람을 기쁘게 하기 위해 상대에게 맞추거나 자신을 깎아내린다.\n",
      "6. 여가 활동을 많이 하지 않는다.\n",
      "7. 자기 관리에 영향을 받는다.\n",
      "\n",
      "이는 낮은 자존감으로 인해 나타나는 영향들을 나열한 것입니다.\n",
      "\n",
      " ################질문################\n",
      "user: Q을 위해 어떤 그림, 음악, 영상 컨텐츠가 위로가 될까?\n",
      "################응답################\n",
      "assistant: 파일 내에서 \"Q을 위해 어떤 그림, 음악, 영상 컨텐츠가 위로가 될까?\"에 대한 구체적인 정보는 찾을 수 없습니다. 파일이 낮은 자존감과 관련된 내용을 다루고 있으므로, Q에게 위로가 될만한 컨텐츠를 제안하기 위해서는 일반적인 지식을 바탕으로 답변드릴 수 있습니다. \n",
      "\n",
      "낮은 자존감을 가진 사람에게는 자기 가치를 높이고 긍정적인 기분을 유발할 수 있는 그림, 음악 또는 영상 컨텐츠가 효과적일 수 있습니다. 예를 들면:\n",
      "\n",
      "- 그림: 자연 풍경이나 동물, 혹은 온기를 느낄 수 있는 가족이나 친구들의 그림이 긍정적인 기분을 유료할 수 있습니다.\n",
      "- 음악: 가사가 긍정적이고 리듬이 상쾌한 음악은 기분을 개선할 수 있습니다.\n",
      "- 영상: 동기부여가 되는 다큐멘터리, 유머가 있는 영화나 TV 프로그램, 자연의 아름다움을 보여주는 영상 등이 자존감을 높일 수 있는 컨텐츠입니다.\n",
      "\n",
      "이런 컨텐츠들은 Q가 스스로를 더 긍정적으로 바라보고 자신을 소중히 여기며 삶의 즐거움을 찾는데 도움을 줄 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "for msg in reversed(messages.data):\n",
    "    if msg.role=='user':\n",
    "        print(\"\\n ################질문################\")\n",
    "    else:\n",
    "        print(\"################응답################\")\n",
    "    print(f\"{msg.role}: {msg.content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assistant와 thread 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete thread\n",
    "response = client.beta.threads.delete(thread.id)\n",
    "print(response)\n",
    "\n",
    "# delete assistant\n",
    "response = client.beta.assistants.delete(tinygrad_assistant.id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
